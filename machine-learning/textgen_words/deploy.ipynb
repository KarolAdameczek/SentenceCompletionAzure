{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "from azureml.core import Experiment, Workspace"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611417376167
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_reloaded = tf.saved_model.load('model/one_step_model')\r\n",
        "\r\n",
        "states = None\r\n",
        "next_char = tf.constant(['sejm'])\r\n",
        "result = [next_char]\r\n",
        "\r\n",
        "for n in range(100):\r\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\r\n",
        "  result.append(next_char)\r\n",
        "\r\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 103 calls to <function recreate_function.<locals>.restored_function_body at 0x7f43c5dd2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 104 calls to <function recreate_function.<locals>.restored_function_body at 0x7f43d4e24ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 105 calls to <function recreate_function.<locals>.restored_function_body at 0x7f43d4e24840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 106 calls to <function recreate_function.<locals>.restored_function_body at 0x7f43c699b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 107 calls to <function recreate_function.<locals>.restored_function_body at 0x7f43c699b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "sejmie takiego słowa w sprawach ?\n",
            "jeśli chodzi o reklamows ‒ dlatego , że stana nie tyle obyta .\n",
            "być m\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1611417384746
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "exp = Experiment(workspace=ws, name='textgen')\r\n",
        "\r\n",
        "run = Run(exp, 'textgen_1611385820_c8bf89c3')"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611417386382
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = run.register_model(model_name='textgen_model', model_path='outputs/model/')"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611417387320
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='deep-learning', subscription_id='fc814e44-1cd5-4ab5-944b-f2255f816d34', resource_group='text-generation'), name=textgen_model, id=textgen_model:5, version=5, tags={}, properties={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611417387566
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gen.py\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    model_root = os.getenv('AZUREML_MODEL_DIR')\r\n",
        "    model_folder = 'model/one_step_model'\r\n",
        "    model = tf.saved_model.load(os.path.join(model_root, model_folder))\r\n",
        " \r\n",
        "    \r\n",
        "def run(input_):\r\n",
        "    json_ = json.loads(input_)\r\n",
        "    next_char = tf.constant([json_[\"data\"]])\r\n",
        "    n = json_['num']\r\n",
        "\r\n",
        "    json_1 = { \"data\" : [] }\r\n",
        "    for i in range(n):\r\n",
        "        states = None\r\n",
        "        next_char = tf.constant([json_[\"data\"]])\r\n",
        "        result = [ next_char ]\r\n",
        "        for n in range(100):\r\n",
        "            next_char, states = model.generate_one_step(next_char, states=states)\r\n",
        "            result.append(next_char)\r\n",
        "        json_1[\"data\"].append(tf.strings.join(result)[0].numpy().decode(\"utf-8\").replace('\\r\\n', \" \"))\r\n",
        "\r\n",
        "    return json_1\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting gen.py\n"
          ]
        }
      ],
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import CondaDependencies\r\n",
        "\r\n",
        "cd = CondaDependencies.create()\r\n",
        "cd.add_conda_package('numpy')\r\n",
        "cd.add_pip_package('tensorflow==2.4.1')\r\n",
        "cd.add_pip_package(\"azureml-defaults\")\r\n",
        "cd.save_to_file(base_directory='./', conda_file_path='myenv.yml')\r\n",
        "\r\n",
        "print(cd.serialize_to_string())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Conda environment specification. The dependencies defined in this file will\r\n",
            "# be automatically provisioned for runs with userManagedDependencies=False.\r\n",
            "\n",
            "# Details about the Conda environment file format:\r\n",
            "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n",
            "\n",
            "name: project_environment\n",
            "dependencies:\n",
            "  # The python interpreter version.\r\n",
            "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
            "- python=3.6.2\n",
            "\n",
            "- pip:\n",
            "  - tensorflow==2.4.1\n",
            "  - azureml-defaults\n",
            "- numpy\n",
            "channels:\n",
            "- anaconda\n",
            "- conda-forge\n",
            "\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611416544761
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.model import Model\r\n",
        "from azureml.core.environment import Environment\r\n",
        "\r\n",
        "\r\n",
        "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\r\n",
        "inference_config = InferenceConfig(entry_script=\"gen.py\", environment=myenv)\r\n",
        "\r\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1,\r\n",
        "                                               auth_enabled=True, # this flag generates API keys to secure access\r\n",
        "                                               memory_gb=1,\r\n",
        "                                               tags={'name': 'textgen', 'framework': 'TfKeras'},\r\n",
        "                                               description='text-generation')\r\n",
        "\r\n",
        "service = Model.deploy(workspace=ws, \r\n",
        "                           name='text-generation8h', \r\n",
        "                           models=[model], \r\n",
        "                           inference_config=inference_config, \r\n",
        "                           deployment_config=aciconfig)\r\n",
        "\r\n",
        "service.wait_for_deployment(True)\r\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running.........."
          ]
        }
      ],
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611416763950
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-01-23T13:26:17,617167768+00:00 - rsyslog/run \n",
            "2021-01-23T13:26:17,617167668+00:00 - iot-server/run \n",
            "2021-01-23T13:26:17,617771094+00:00 - gunicorn/run \n",
            "2021-01-23T13:26:17,635322733+00:00 - nginx/run \n",
            "/usr/sbin/nginx: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "Starting gunicorn 19.9.0\n",
            "Listening at: http://127.0.0.1:31311 (11)\n",
            "Using worker: sync\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 30\n",
            "2021-01-23 13:26:18.865925: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib:/azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib:\n",
            "2021-01-23 13:26:18.865961: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
            "2021-01-23T13:26:19,479688997+00:00 - iot-server/finish 1 0\n",
            "2021-01-23T13:26:19,480817445+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-01-23 13:26:21,415 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2021-01-23 13:26:21,415 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2021-01-23 13:26:21,415 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2021-01-23 13:26:21,415 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2021-01-23 13:26:21.558755: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-23 13:26:21.559115: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib:/azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib:\n",
            "2021-01-23 13:26:21.559141: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2021-01-23 13:26:21.559171: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wk-caas-6ffee747ac1b4915b918b8d3897ea5b7-dd584c42a219b66da90dcc): /proc/driver/nvidia/version does not exist\n",
            "2021-01-23 13:26:21.559375: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-01-23 13:26:21.559513: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-23 13:26:23.581277: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-01-23 13:26:23.581936: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2397220000 Hz\n",
            "2021-01-23 13:26:26,324 | root | INFO | Users's init has completed successfully\n",
            "Users's init has completed successfully\n",
            "2021-01-23 13:26:26,326 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-01-23 13:26:26,326 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-01-23 13:26:26,327 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-01-23 13:26:26,336 | root | INFO | Swagger file not present\n",
            "Swagger file not present\n",
            "2021-01-23 13:26:26,336 | root | INFO | 404\n",
            "404\n",
            "127.0.0.1 - - [23/Jan/2021:13:26:26 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
            "2021-01-23 13:26:29,593 | root | INFO | Swagger file not present\n",
            "Swagger file not present\n",
            "2021-01-23 13:26:29,593 | root | INFO | 404\n",
            "404\n",
            "127.0.0.1 - - [23/Jan/2021:13:26:29 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
            "2021-01-23 13:26:42,731 | root | INFO | Swagger file not present\n",
            "Swagger file not present\n",
            "2021-01-23 13:26:42,731 | root | INFO | 404\n",
            "404\n",
            "127.0.0.1 - - [23/Jan/2021:13:26:42 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
            "\n"
          ]
        }
      ],
      "execution_count": 86,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611408584343
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}