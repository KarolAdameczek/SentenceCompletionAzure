{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "from azureml.core import Experiment, Workspace"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611745756889
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "exp = Experiment(workspace=ws, name='textgen-lstm')\r\n",
        "\r\n",
        "run = Run(exp, 'textgen-lstm_1611696706_5b26c855')"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611745764170
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model folder in the current directory\r\n",
        "os.makedirs('./model', exist_ok=True)\r\n",
        "\r\n",
        "for f in run.get_file_names():\r\n",
        "    if f.startswith('outputs/'):\r\n",
        "        print(f.replace('outputs/model/', \"\"))\r\n",
        "        output_path = os.path.join('./model/', f.replace('outputs/model/', \"\"))\r\n",
        "        print('Downloading from {} to {} ...'.format(f, output_path))\r\n",
        "        run.download_file(name=f, output_file_path=output_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model/saved_model.pb\n",
            "Downloading from outputs/model/model/saved_model.pb to ./model/model/saved_model.pb ...\n",
            "model/variables/variables.data-00000-of-00001\n",
            "Downloading from outputs/model/model/variables/variables.data-00000-of-00001 to ./model/model/variables/variables.data-00000-of-00001 ...\n",
            "model/variables/variables.index\n",
            "Downloading from outputs/model/model/variables/variables.index to ./model/model/variables/variables.index ...\n",
            "one_step_model/saved_model.pb\n",
            "Downloading from outputs/model/one_step_model/saved_model.pb to ./model/one_step_model/saved_model.pb ...\n",
            "one_step_model/variables/variables.data-00000-of-00001\n",
            "Downloading from outputs/model/one_step_model/variables/variables.data-00000-of-00001 to ./model/one_step_model/variables/variables.data-00000-of-00001 ...\n",
            "one_step_model/variables/variables.index\n",
            "Downloading from outputs/model/one_step_model/variables/variables.index to ./model/one_step_model/variables/variables.index ...\n",
            "outputs/training_checkpoints/checkpoint\n",
            "Downloading from outputs/training_checkpoints/checkpoint to ./model/outputs/training_checkpoints/checkpoint ...\n",
            "outputs/training_checkpoints/ckpt_1.data-00000-of-00001\n",
            "Downloading from outputs/training_checkpoints/ckpt_1.data-00000-of-00001 to ./model/outputs/training_checkpoints/ckpt_1.data-00000-of-00001 ...\n",
            "outputs/training_checkpoints/ckpt_1.index\n",
            "Downloading from outputs/training_checkpoints/ckpt_1.index to ./model/outputs/training_checkpoints/ckpt_1.index ...\n",
            "outputs/training_checkpoints/ckpt_1_temp_ffff69fb13fc40c180bf78806e516bc1/part-00000-of-00001.index\n",
            "Downloading from outputs/training_checkpoints/ckpt_1_temp_ffff69fb13fc40c180bf78806e516bc1/part-00000-of-00001.index to ./model/outputs/training_checkpoints/ckpt_1_temp_ffff69fb13fc40c180bf78806e516bc1/part-00000-of-00001.index ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to download file with error: The specified blob does not exist. ErrorCode: BlobNotFound\n",
            "<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobNotFound</Code><Message>The specified blob does not exist.\n",
            "RequestId:7c5e9fb1-e01e-0039-4b9d-f455a3000000\n",
            "Time:2021-01-27T11:16:27.5321604Z</Message></Error>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AzureMLException",
          "evalue": "AzureMLException:\n\tMessage: Download of file failed with error: The specified blob does not exist. ErrorCode: BlobNotFound\n<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobNotFound</Code><Message>The specified blob does not exist.\nRequestId:7c5e9fb1-e01e-0039-4b9d-f455a3000000\nTime:2021-01-27T11:16:27.5321604Z</Message></Error>\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Download of file failed with error: The specified blob does not exist. ErrorCode: BlobNotFound\\n<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?><Error><Code>BlobNotFound</Code><Message>The specified blob does not exist.\\nRequestId:7c5e9fb1-e01e-0039-4b9d-f455a3000000\\nTime:2021-01-27T11:16:27.5321604Z</Message></Error>\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAzureMissingResourceHttpError\u001b[0m             Traceback (most recent call last)",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_file_utils/file_utils.py\u001b[0m in \u001b[0;36m_retry\u001b[0;34m(exec_func, clean_up_func, max_retries, exceptions)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexec_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrequest_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_file_utils/file_utils.py\u001b[0m in \u001b[0;36mexec_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m                                                           \u001b[0mmax_connections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_concurrency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                                           validate_content=_validate_check_sum)\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0mfile_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_vendor/azure_storage/blob/baseblobservice.py\u001b[0m in \u001b[0;36mget_blob_to_path\u001b[0;34m(self, container_name, blob_name, file_path, open_mode, snapshot, start_range, end_range, validate_content, progress_callback, max_connections, lease_id, if_modified_since, if_unmodified_since, if_match, if_none_match, timeout)\u001b[0m\n\u001b[1;32m   1871\u001b[0m                 \u001b[0mif_none_match\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1872\u001b[0;31m                 timeout)\n\u001b[0m\u001b[1;32m   1873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_vendor/azure_storage/blob/baseblobservice.py\u001b[0m in \u001b[0;36mget_blob_to_stream\u001b[0;34m(self, container_name, blob_name, stream, snapshot, start_range, end_range, validate_content, progress_callback, max_connections, lease_id, if_modified_since, if_unmodified_since, if_match, if_none_match, timeout)\u001b[0m\n\u001b[1;32m   2043\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_vendor/azure_storage/blob/baseblobservice.py\u001b[0m in \u001b[0;36mget_blob_to_stream\u001b[0;34m(self, container_name, blob_name, stream, snapshot, start_range, end_range, validate_content, progress_callback, max_connections, lease_id, if_modified_since, if_unmodified_since, if_match, if_none_match, timeout)\u001b[0m\n\u001b[1;32m   2011\u001b[0m                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2012\u001b[0;31m                                   _context=operation_context)\n\u001b[0m\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_vendor/azure_storage/blob/baseblobservice.py\u001b[0m in \u001b[0;36m_get_blob\u001b[0;34m(self, container_name, blob_name, snapshot, start_range, end_range, validate_content, lease_id, if_modified_since, if_unmodified_since, if_match, if_none_match, timeout, _context)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                                       start_offset, end_offset],\n\u001b[0;32m-> 1750\u001b[0;31m                                      operation_context=_context)\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_vendor/azure_storage/common/storageclient.py\u001b[0m in \u001b[0;36m_perform_request\u001b[0;34m(self, request, parser, parser_args, operation_context, expected_errors)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                  exception_str_in_one_line)\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_vendor/azure_storage/common/storageclient.py\u001b[0m in \u001b[0;36m_perform_request\u001b[0;34m(self, request, parser, parser_args, operation_context, expected_errors)\u001b[0m\n\u001b[1;32m    305\u001b[0m                     \u001b[0mretry_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_vendor/azure_storage/common/storageclient.py\u001b[0m in \u001b[0;36m_perform_request\u001b[0;34m(self, request, parser, parser_args, operation_context, expected_errors)\u001b[0m\n\u001b[1;32m    291\u001b[0m                         _http_error_handler(\n\u001b[0;32m--> 292\u001b[0;31m                             HTTPError(response.status, response.message, response.headers, response.body))\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_vendor/azure_storage/common/_error.py\u001b[0m in \u001b[0;36m_http_error_handler\u001b[0;34m(http_error)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAzureMissingResourceHttpError\u001b[0m: The specified blob does not exist. ErrorCode: BlobNotFound\n<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobNotFound</Code><Message>The specified blob does not exist.\nRequestId:7c5e9fb1-e01e-0039-4b9d-f455a3000000\nTime:2021-01-27T11:16:27.5321604Z</Message></Error>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAzureMLException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cf2f0c3c2bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs/model/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading from {} to {} ...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                                      \"therefore, the {} cannot upload files, or log file backed metrics.\".format(\n\u001b[1;32m     49\u001b[0m                                          self, self.__class__.__name__))\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, name, output_file_path, _validate_checksum)\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         self._client.artifacts.download_artifact(RUN_ORIGIN, self._container, name, output_file_path,\n\u001b[0;32m-> 1974\u001b[0;31m                                                  _validate_checksum)\n\u001b[0m\u001b[1;32m   1975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_check_for_data_container_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/artifacts_client.py\u001b[0m in \u001b[0;36mdownload_artifact\u001b[0;34m(self, origin, container, path, output_file_path, _validate_checksum)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0muri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_uri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             self._execute_func(download_file, uri, output_file_path, session=self.session,\n\u001b[0;32m--> 261\u001b[0;31m                                _validate_check_sum=_validate_checksum)\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHttpOperationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moperation_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_http_operation_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/clientbase.py\u001b[0m in \u001b[0;36m_execute_func\u001b[0;34m(cls, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;31m# reset the backoff from 32 seconds to 1 second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         return cls._execute_func_internal(\n\u001b[0;32m--> 369\u001b[0;31m             DEFAULT_SHORT_BACKOFF, DEFAULT_RETRIES, module_logger, func, _noop_reset, *args, **kwargs)\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/clientbase.py\u001b[0m in \u001b[0;36m_execute_func_internal\u001b[0;34m(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0mleft_retry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_off\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_retry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_retry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mreset_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reset_func is expected to undo any side effects from a failed func call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/clientbase.py\u001b[0m in \u001b[0;36m_handle_retry\u001b[0;34m(cls, back_off, left_retry, total_retry, error, logger, func)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;31m# the case 4 will be handled here by adding ConnectTime in the RETRY_EXCEPTIONS.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;31m# also cover case 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_retry_delay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_off\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_retry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_retry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/clientbase.py\u001b[0m in \u001b[0;36m_execute_func_internal\u001b[0;34m(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ClientBase: Calling {} with url {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                 if (isinstance(response, Response) and cls._is_retryable_status_code(response.status_code) and\n\u001b[1;32m    354\u001b[0m                         left_retry > 0):\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_file_utils/file_utils.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(source_uri, path, max_retries, stream, protocol, session, _validate_check_sum, max_concurrency)\u001b[0m\n\u001b[1;32m    219\u001b[0m                                        'present in blob.'.format(file_size, content_length))\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;31m# download using requests.Session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_file_utils/file_utils.py\u001b[0m in \u001b[0;36m_retry\u001b[0;34m(exec_func, clean_up_func, max_retries, exceptions)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mmodule_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to download file with error: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAzureMLException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Download of file failed with error: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mclean_up_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAzureMLException\u001b[0m: AzureMLException:\n\tMessage: Download of file failed with error: The specified blob does not exist. ErrorCode: BlobNotFound\n<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobNotFound</Code><Message>The specified blob does not exist.\nRequestId:7c5e9fb1-e01e-0039-4b9d-f455a3000000\nTime:2021-01-27T11:16:27.5321604Z</Message></Error>\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Download of file failed with error: The specified blob does not exist. ErrorCode: BlobNotFound\\n<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?><Error><Code>BlobNotFound</Code><Message>The specified blob does not exist.\\nRequestId:7c5e9fb1-e01e-0039-4b9d-f455a3000000\\nTime:2021-01-27T11:16:27.5321604Z</Message></Error>\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611706234889
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_reloaded = tf.saved_model.load('model/one_step_model')"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "states = None\r\n",
        "next_char = tf.constant(['pan to jednak'])\r\n",
        "result = [x+' ' for x in next_char]\r\n",
        "\r\n",
        "for n in range(6):\r\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\r\n",
        "  result.append(next_char+' ')\r\n",
        "\r\n",
        "result = tf.strings.join(result)\r\n",
        "\r\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'one_step_reloaded' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-308ccf3daa7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_step_reloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'one_step_reloaded' is not defined"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611700103573
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = run.register_model(model_name='textgen_model', model_path='outputs/model/')"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611706444427
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='sentencecompletion', subscription_id='5334814e-153c-45f0-9557-00aa820611b9', resource_group='SentenceCompletionAzure'), name=textgen_model, id=textgen_model:1, version=1, tags={}, properties={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611706446104
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gen.py\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    model_root = os.getenv('AZUREML_MODEL_DIR')\r\n",
        "    model_folder = 'model/one_step_model'\r\n",
        "    model = tf.saved_model.load(os.path.join(model_root, model_folder))\r\n",
        " \r\n",
        "    \r\n",
        "def run(input_):\r\n",
        "    json_ = json.loads(input_)\r\n",
        "    next_word = tf.constant([json_[\"data\"]])\r\n",
        "    n = json_['num']\r\n",
        "\r\n",
        "    json_1 = { \"data\" : [] }\r\n",
        "    for i in range(n):\r\n",
        "        states = None\r\n",
        "        next_word = tf.constant(['pan to jednak'])\r\n",
        "        result = [x+' ' for x in next_word]\r\n",
        "\r\n",
        "        for n in range(6):\r\n",
        "            next_word, states = model.generate_one_step(next_word, states=states)\r\n",
        "            result.append(next_word+' ')\r\n",
        "\r\n",
        "        json_1[\"data\"].append(tf.strings.join(result)[0].numpy().decode(\"utf-8\").replace('\\r\\n', \" \"))\r\n",
        "\r\n",
        "    return json_1\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gen.py\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import CondaDependencies\r\n",
        "\r\n",
        "cd = CondaDependencies.create()\r\n",
        "cd.add_conda_package('numpy')\r\n",
        "cd.add_pip_package('tensorflow==2.4.1')\r\n",
        "cd.add_pip_package(\"azureml-defaults\")\r\n",
        "cd.save_to_file(base_directory='./', conda_file_path='myenv.yml')\r\n",
        "\r\n",
        "print(cd.serialize_to_string())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Conda environment specification. The dependencies defined in this file will\r\n",
            "# be automatically provisioned for runs with userManagedDependencies=False.\r\n",
            "\n",
            "# Details about the Conda environment file format:\r\n",
            "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n",
            "\n",
            "name: project_environment\n",
            "dependencies:\n",
            "  # The python interpreter version.\r\n",
            "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
            "- python=3.6.2\n",
            "\n",
            "- pip:\n",
            "  - tensorflow==2.4.1\n",
            "  - azureml-defaults\n",
            "- numpy\n",
            "channels:\n",
            "- anaconda\n",
            "- conda-forge\n",
            "\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611706449600
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.model import Model\r\n",
        "from azureml.core.environment import Environment\r\n",
        "\r\n",
        "\r\n",
        "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\r\n",
        "inference_config = InferenceConfig(entry_script=\"gen.py\", environment=myenv)\r\n",
        "\r\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=3.8,\r\n",
        "                                               auth_enabled=True, \r\n",
        "                                               memory_gb=15,\r\n",
        "                                               tags={'name': 'textgen', 'framework': 'TfKeras'},\r\n",
        "                                               description='text-generation')\r\n",
        "\r\n",
        "service = Model.deploy(workspace=ws, \r\n",
        "                           name='text-generation-c', \r\n",
        "                           models=[model], \r\n",
        "                           inference_config=inference_config, \r\n",
        "                           deployment_config=aciconfig)\r\n",
        "\r\n",
        "service.wait_for_deployment(True)\r\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running..................................................................................................................................................................................................................................\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n",
            "Healthy\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611707617303
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-01-27T00:32:25,878851108+00:00 - gunicorn/run \n",
            "2021-01-27T00:32:25,880882594+00:00 - rsyslog/run \n",
            "2021-01-27T00:32:25,886901753+00:00 - iot-server/run \n",
            "2021-01-27T00:32:25,889988831+00:00 - nginx/run \n",
            "/usr/sbin/nginx: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
            "2021-01-27T00:32:26,006732523+00:00 - iot-server/finish 1 0\n",
            "2021-01-27T00:32:26,008210013+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
            "Starting gunicorn 19.9.0\n",
            "Listening at: http://127.0.0.1:31311 (11)\n",
            "Using worker: sync\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 42\n",
            "2021-01-27 00:32:26.763059: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib:/azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib:\n",
            "2021-01-27 00:32:26.763109: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-01-27 00:32:29,373 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2021-01-27 00:32:29,373 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2021-01-27 00:32:29,373 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2021-01-27 00:32:29,373 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2021-01-27 00:32:31.035396: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-27 00:32:31.035855: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib:/azureml-envs/azureml_4f0880b375e57ffe758b94a0c72756a7/lib:\n",
            "2021-01-27 00:32:31.035887: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2021-01-27 00:32:31.035946: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wk-caas-7ca80a9c572f47c8b527cc767d6bb310-8e82476bf5584c787c3c92): /proc/driver/nvidia/version does not exist\n",
            "2021-01-27 00:32:31.036240: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-01-27 00:32:31.037399: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-27 00:32:33.517537: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1331474432 exceeds 10% of free system memory.\n",
            "2021-01-27 00:32:33.691637: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1331474432 exceeds 10% of free system memory.\n",
            "2021-01-27 00:32:33.899829: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-01-27 00:32:33.900582: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2294685000 Hz\n",
            "2021-01-27 00:32:33.926403: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1331474432 exceeds 10% of free system memory.\n",
            "2021-01-27 00:32:47.356199: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1331474432 exceeds 10% of free system memory.\n",
            "2021-01-27 00:33:01.274441: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1331474432 exceeds 10% of free system memory.\n",
            "2021-01-27 00:33:20,353 | root | INFO | Users's init has completed successfully\n",
            "Users's init has completed successfully\n",
            "2021-01-27 00:33:20,356 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-01-27 00:33:20,356 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-01-27 00:33:20,357 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-01-27 00:33:31,620 | root | INFO | Swagger file not present\n",
            "Swagger file not present\n",
            "2021-01-27 00:33:31,620 | root | INFO | 404\n",
            "404\n",
            "127.0.0.1 - - [27/Jan/2021:00:33:31 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
            "2021-01-27 00:33:34,301 | root | INFO | Swagger file not present\n",
            "Swagger file not present\n",
            "2021-01-27 00:33:34,301 | root | INFO | 404\n",
            "404\n",
            "127.0.0.1 - - [27/Jan/2021:00:33:34 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
            "2021-01-27 00:33:35,997 | root | INFO | Swagger file not present\n",
            "Swagger file not present\n",
            "2021-01-27 00:33:35,998 | root | INFO | 404\n",
            "404\n",
            "127.0.0.1 - - [27/Jan/2021:00:33:35 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
            "\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611707632294
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}