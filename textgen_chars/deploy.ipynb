{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "from azureml.core import Experiment, Workspace"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611694077167
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "exp = Experiment(workspace=ws, name='textgen')\r\n",
        "\r\n",
        "run = Run(exp, 'textgen_1611659464_8c9caec1')"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611699104532
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model folder in the current directory\r\n",
        "os.makedirs('./model', exist_ok=True)\r\n",
        "\r\n",
        "for f in run.get_file_names():\r\n",
        "    if f.startswith('outputs/'):\r\n",
        "        print(f.replace('outputs/model/', \"\"))\r\n",
        "        output_path = os.path.join('./model/', f.replace('outputs/model/', \"\"))\r\n",
        "        print('Downloading from {} to {} ...'.format(f, output_path))\r\n",
        "        run.download_file(name=f, output_file_path=output_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one_step_model/saved_model.pb\n",
            "Downloading from outputs/model/one_step_model/saved_model.pb to ./model/one_step_model/saved_model.pb ...\n",
            "one_step_model/variables/variables.data-00000-of-00001\n",
            "Downloading from outputs/model/one_step_model/variables/variables.data-00000-of-00001 to ./model/one_step_model/variables/variables.data-00000-of-00001 ...\n",
            "one_step_model/variables/variables.index\n",
            "Downloading from outputs/model/one_step_model/variables/variables.index to ./model/one_step_model/variables/variables.index ...\n",
            "outputs/training_checkpoints/checkpoint\n",
            "Downloading from outputs/training_checkpoints/checkpoint to ./model/outputs/training_checkpoints/checkpoint ...\n",
            "outputs/training_checkpoints/ckpt_1.data-00000-of-00001\n",
            "Downloading from outputs/training_checkpoints/ckpt_1.data-00000-of-00001 to ./model/outputs/training_checkpoints/ckpt_1.data-00000-of-00001 ...\n",
            "outputs/training_checkpoints/ckpt_1.index\n",
            "Downloading from outputs/training_checkpoints/ckpt_1.index to ./model/outputs/training_checkpoints/ckpt_1.index ...\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611699910684
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_reloaded = tf.saved_model.load('model/one_step_model')\r\n",
        "\r\n",
        "states1 = None\r\n",
        "states2 = None\r\n",
        "next_char = tf.constant(['sejm'])\r\n",
        "result = [next_char]\r\n",
        "\r\n",
        "for n in range(100):\r\n",
        "  next_char, states1, states2 = one_step_reloaded.generate_one_step(next_char, states1=states1, states2=states2)\r\n",
        "  result.append(next_char)\r\n",
        "\r\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fbff4f03400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fbff4f0c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x7fbff4f0c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7fbff4effd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc0052897b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc00527e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fbff4eff378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fbff4eff378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "sejmowi wydaje się , że nie było .\n",
            "jak pan zainteresował się w stosunku do takiego poglądu , że nie cho\n"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611700103573
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = run.register_model(model_name='textgen_model', model_path='outputs/model/')"
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611705320432
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='textgen', subscription_id='09598021-a61a-4f74-bcdd-f6bf71f9396b', resource_group='textgen'), name=textgen_model, id=textgen_model:3, version=3, tags={}, properties={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611705320735
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gen.py\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    model_root = os.getenv('AZUREML_MODEL_DIR')\r\n",
        "    model_folder = 'model/one_step_model'\r\n",
        "    model = tf.saved_model.load(os.path.join(model_root, model_folder))\r\n",
        " \r\n",
        "    \r\n",
        "def run(input_):\r\n",
        "    json_ = json.loads(input_)\r\n",
        "    next_char = tf.constant([json_[\"data\"]])\r\n",
        "    n = json_['num']\r\n",
        "\r\n",
        "    json_1 = { \"data\" : [] }\r\n",
        "    for i in range(n):\r\n",
        "        states = None\r\n",
        "        next_char = tf.constant([json_[\"data\"]])\r\n",
        "        result = [ next_char ]\r\n",
        "        for n in range(100):\r\n",
        "            next_char, states = model.generate_one_step(next_char, states=states)\r\n",
        "            result.append(next_char)\r\n",
        "        json_1[\"data\"].append(tf.strings.join(result)[0].numpy().decode(\"utf-8\").replace('\\r\\n', \" \"))\r\n",
        "\r\n",
        "    return json_1\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting gen.py\n"
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import CondaDependencies\r\n",
        "\r\n",
        "cd = CondaDependencies.create()\r\n",
        "cd.add_conda_package('numpy')\r\n",
        "cd.add_pip_package('tensorflow==2.4.1')\r\n",
        "cd.add_pip_package(\"azureml-defaults\")\r\n",
        "cd.save_to_file(base_directory='./', conda_file_path='myenv.yml')\r\n",
        "\r\n",
        "print(cd.serialize_to_string())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611702366502
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.model import Model\r\n",
        "from azureml.core.environment import Environment\r\n",
        "\r\n",
        "\r\n",
        "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\r\n",
        "inference_config = InferenceConfig(entry_script=\"gen.py\", environment=myenv)\r\n",
        "\r\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=3.8,\r\n",
        "                                               auth_enabled=True, \r\n",
        "                                               memory_gb=15,\r\n",
        "                                               tags={'name': 'textgen', 'framework': 'TfKeras'},\r\n",
        "                                               description='text-generation')\r\n",
        "\r\n",
        "service = Model.deploy(workspace=ws, \r\n",
        "                           name='text-generation-c', \r\n",
        "                           models=[model], \r\n",
        "                           inference_config=inference_config, \r\n",
        "                           deployment_config=aciconfig)\r\n",
        "\r\n",
        "service.wait_for_deployment(True)\r\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running.............................................."
          ]
        }
      ],
      "execution_count": 36,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611416763950
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-01-26T22:46:29,910665491+00:00 - iot-server/run \n",
            "2021-01-26T22:46:29,915810227+00:00 - nginx/run \n",
            "2021-01-26T22:46:29,915810327+00:00 - gunicorn/run \n",
            "2021-01-26T22:46:29,912691366+00:00 - rsyslog/run \n",
            "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
            "2021-01-26T22:46:30,057568049+00:00 - iot-server/finish 1 0\n",
            "2021-01-26T22:46:30,058938732+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
            "Starting gunicorn 19.9.0\n",
            "Listening at: http://127.0.0.1:31311 (16)\n",
            "Using worker: sync\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 40\n",
            "2021-01-26 22:46:30.845791: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib:/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib:\n",
            "2021-01-26 22:46:30.846020: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-01-26 22:46:33,131 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2021-01-26 22:46:33,132 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2021-01-26 22:46:33,132 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2021-01-26 22:46:33,132 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2021-01-26 22:46:33.479277: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib:/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib:\n",
            "2021-01-26 22:46:33.479320: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2021-01-26 22:46:33.479377: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wk-caas-f453acf235714fe18fcd099862e1fbad-9617db30db35149f2c02d3): /proc/driver/nvidia/version does not exist\n",
            "2021-01-26 22:46:33.479714: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-01-26 22:46:33.488925: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2294680000 Hz\n",
            "2021-01-26 22:46:33.489251: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561c5ee03ec0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-01-26 22:46:33.489275: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-01-26 22:46:38,132 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "2021-01-26 22:46:38,134 | root | ERROR | Encountered Exception Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/aml_blueprint.py\", line 177, in register\n",
            "    main.init()\n",
            "  File \"/var/azureml-app/gen.py\", line 12, in init\n",
            "    model = tf.saved_model.load(os.path.join(model_root, model_folder))\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\", line 603, in load\n",
            "    return load_internal(export_dir, tags, options)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\", line 633, in load_internal\n",
            "    ckpt_options)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\", line 131, in __init__\n",
            "    self._restore_checkpoint()\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\", line 330, in _restore_checkpoint\n",
            "    load_status = saver.restore(variables_path, self._checkpoint_options)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py\", line 1320, in restore\n",
            "    checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\", line 209, in restore\n",
            "    restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\", line 914, in _restore_from_checkpoint_position\n",
            "    tensor_saveables, python_saveables))\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py\", line 290, in restore_saveables\n",
            "    tensor_saveables)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 361, in validate_and_slice_inputs\n",
            "    _add_saveable(saveables, seen_ops, converted_saveable_object)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 331, in _add_saveable\n",
            "    saveable.name)\n",
            "ValueError: The same saveable will be restored with two names: ids_from_chars/_table/.ATTRIBUTES/table\n",
            "\n",
            "Encountered Exception Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/aml_blueprint.py\", line 177, in register\n",
            "    main.init()\n",
            "  File \"/var/azureml-app/gen.py\", line 12, in init\n",
            "    model = tf.saved_model.load(os.path.join(model_root, model_folder))\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\", line 603, in load\n",
            "    return load_internal(export_dir, tags, options)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\", line 633, in load_internal\n",
            "    ckpt_options)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\", line 131, in __init__\n",
            "    self._restore_checkpoint()\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\", line 330, in _restore_checkpoint\n",
            "    load_status = saver.restore(variables_path, self._checkpoint_options)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py\", line 1320, in restore\n",
            "    checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\", line 209, in restore\n",
            "    restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\", line 914, in _restore_from_checkpoint_position\n",
            "    tensor_saveables, python_saveables))\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py\", line 290, in restore_saveables\n",
            "    tensor_saveables)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 361, in validate_and_slice_inputs\n",
            "    _add_saveable(saveables, seen_ops, converted_saveable_object)\n",
            "  File \"/azureml-envs/azureml_849829b8f15789b45fa01a1c415d6f58/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 331, in _add_saveable\n",
            "    saveable.name)\n",
            "ValueError: The same saveable will be restored with two names: ids_from_chars/_table/.ATTRIBUTES/table\n",
            "\n",
            "Worker exiting (pid: 40)\n",
            "Shutting down: Master\n",
            "Reason: Worker failed to boot.\n",
            "2021-01-26T22:46:38,921400979+00:00 - gunicorn/finish 3 0\n",
            "2021-01-26T22:46:38,922724363+00:00 - Exit code 3 is not normal. Killing image.\n",
            "\n"
          ]
        }
      ],
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611701244927
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}